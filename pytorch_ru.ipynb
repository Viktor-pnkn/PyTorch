{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Примеры вычислений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :\n",
      " [[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n",
      "add 5 :\n",
      "[[ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]\n",
      " [17 18 19 20]]\n",
      "X*X^T  :\n",
      " [[ 14  38  62  86]\n",
      " [ 38 126 214 302]\n",
      " [ 62 214 366 518]\n",
      " [ 86 302 518 734]]\n",
      "mean over cols :\n",
      "[ 1.5  5.5  9.5 13.5]\n",
      "cumsum of cols :\n",
      "[[ 0  1  2  3]\n",
      " [ 4  6  8 10]\n",
      " [12 15 18 21]\n",
      " [24 28 32 36]]\n"
     ]
    }
   ],
   "source": [
    "# numpy world\n",
    "\n",
    "x = np.arange(16).reshape(4, 4)\n",
    "\n",
    "print(\"X :\\n %s\" % x)\n",
    "print(\"add 5 :\\n%s\" % (x + 5))\n",
    "print(\"X*X^T  :\\n\", np.dot(x, x.T))\n",
    "print(\"mean over cols :\\n%s\" % (x.mean(axis=-1)))\n",
    "print(\"cumsum of cols :\\n%s\" % (np.cumsum(x, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of y: <class 'torch.Tensor'>\n",
      "Type of y <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# pytorch world\n",
    "\n",
    "x = np.arange(16).reshape(4, 4)\n",
    "\n",
    "y = torch.from_numpy(x)\n",
    "print('Type of y:', type(y))\n",
    "y = torch.from_numpy(x).type(torch.FloatTensor)\n",
    "print('Type of y', type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of x: <class 'torch.Tensor'>\n",
      "X :\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n",
      "add 5 :\n",
      "tensor([[ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.],\n",
      "        [13., 14., 15., 16.],\n",
      "        [17., 18., 19., 20.]])\n",
      "X*X^T  :\n",
      " tensor([[ 14.,  38.,  62.,  86.],\n",
      "        [ 38., 126., 214., 302.],\n",
      "        [ 62., 214., 366., 518.],\n",
      "        [ 86., 302., 518., 734.]])\n",
      "mean over cols :\n",
      " tensor([ 1.5000,  5.5000,  9.5000, 13.5000])\n",
      "cumsum of cols :\n",
      " tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  6.,  8., 10.],\n",
      "        [12., 15., 18., 21.],\n",
      "        [24., 28., 32., 36.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 16).view(4, 4).float()\n",
    "print('Type of x:', type(x))\n",
    "\n",
    "print(\"X :\\n%s\" % x)\n",
    "print(\"add 5 :\\n%s\" % (x + 5))\n",
    "print(\"X*X^T  :\\n\", torch.matmul(x, x.transpose(1, 0)))\n",
    "print(\"mean over cols :\\n\", torch.mean(x, dim=-1))\n",
    "print(\"cumsum of cols :\\n\", torch.cumsum(x, dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy и Pytorch\n",
    "\n",
    "Numpy и Pytorch не требуют предварительной компиляции графа вычислений.\n",
    "\n",
    "Для отладки можно использовать `pdb` или вывод через `print`.\n",
    "\n",
    "Методы NumPy и Pytorch в целом похожи, но есть небольшие отличия:\n",
    "\n",
    "```\n",
    "x.reshape([1,2,8]) -> x.view(1,2,8)\n",
    "x.sum(axis=-1) -> x.sum(dim=-1)\n",
    "x.astype('int64') -> x.type(torch.LongTensor)\n",
    "```\n",
    "\n",
    "Также легко конвертировать данные между форматами NumPy и Pytorch:\n",
    "\n",
    "```\n",
    "torch.from_numpy(npx) -- returns Tensor\n",
    "tt.numpy() -- returns Numpy Array\n",
    "```\n",
    "\n",
    "Troubleshooting:\n",
    "- читаем документацию\n",
    "- гуглим (stackoverflow / туториалы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.        1.        0.9999999 1.        0.9999999 1.        1.\n",
      " 1.        1.        1.        1.        1.        1.        1.\n",
      " 1.        1.       ]\n"
     ]
    }
   ],
   "source": [
    "x = torch.linspace(0, 2 * np.pi, 16)\n",
    "\n",
    "# Mini-task: compute a vector of sin^2(x) + cos^2(x)\n",
    "out = torch.sin(x)**2 + torch.cos(x)**2\n",
    "\n",
    "print(out.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-place операции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда мы работаем с большими тензорами, для достижения максимальлной производительности память должна использоваться максимально эффективно. Некоторые операции создают новый объект, являющийся результатом вычислений. Операции, которые просто изменяют объект, не создавая новых, называют in-place операциями. В Pytorch такие операции обычно заканчиваются нижним подчёркиванием:\n",
    "```\n",
    "x.exp()   # not-in-place operation\n",
    "x.exp_()  # in-place operation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not-in-place:\n",
      "\tx.exp():\t\t [ 1.         2.7182817  7.389056  20.085537 ]\n",
      "\tx:\t\t\t [0. 1. 2. 3.]\n",
      "In-place:\n",
      "\tx.exp_():\t\t [ 1.         2.7182817  7.389056  20.085537 ]\n",
      "\tx after x.exp_():\t [ 1.         2.7182817  7.389056  20.085537 ]\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(4).float()\n",
    "print('Not-in-place:')\n",
    "print('\\tx.exp():\\t\\t', x.exp().numpy())\n",
    "print('\\tx:\\t\\t\\t', x.numpy())\n",
    "print('In-place:')\n",
    "print('\\tx.exp_():\\t\\t', x.exp_().numpy())\n",
    "print('\\tx after x.exp_():\\t', x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [4 6]]\n",
      "[[0 2]\n",
      " [4 6]]\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 4).view(2, 2)\n",
    "y = torch.arange(4, 8).view(2, 2)\n",
    "z = torch.arange(8, 12).view(2, 2)\n",
    "\n",
    "# Not-in-place:\n",
    "u = x + 2 * y - z    # 3 аллокации для промежуточных результатов\n",
    "print(u.numpy())\n",
    "\n",
    "# In-place\n",
    "u = y.clone()        # 1 аллокация\n",
    "u.mul_(2)\n",
    "u.add_(x)\n",
    "u.sub_(z)\n",
    "print(u.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторные вычисления в pytorch (аналогично numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "b: tensor([[1., 0., 1., 0.]])\n",
      "a + b: tensor([[2., 1., 2., 1.],\n",
      "        [2., 1., 2., 1.],\n",
      "        [2., 1., 2., 1.],\n",
      "        [3., 2., 3., 2.]])\n",
      "c: tensor([[ 0.8252, -0.6722, -0.9953,  1.7612],\n",
      "        [ 0.5370, -1.1465, -0.8466,  1.1356],\n",
      "        [ 1.4756,  0.1504, -0.1369,  0.5969],\n",
      "        [-2.6517, -0.6152,  0.7552, -1.2252]])\n",
      "b + c: tensor([[ 1.8252, -0.6722,  0.0047,  1.7612],\n",
      "        [ 1.5370, -1.1465,  0.1534,  1.1356],\n",
      "        [ 2.4756,  0.1504,  0.8631,  0.5969],\n",
      "        [-1.6517, -0.6152,  1.7552, -1.2252]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([1, 1, 1, 2]).view(4, 1)\n",
    "b = torch.Tensor([1, 0, 1, 0]).view(1, 4)\n",
    "c = torch.randn(16).view(4, 4)\n",
    "print('a:', a)\n",
    "print('b:', b)\n",
    "print('a + b:', a + b)\n",
    "print('c:', c)\n",
    "print('b + c:', b + c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information see http://pytorch.org/docs/master/notes/broadcasting.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание #1: Тензоры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дано 100 объектов, каждый из которых есть 10-мерный вектор. Также даны 5 точек в данном 10-мерном пространстве. Объекты и точки представлены в матрицах X и Y соответственно.\n",
    "\n",
    "Для каждого объекта из X необходимо найти индекс ближайшей точки из Y, используя только тензорные операции (циклы, рекурсия и т.д. запрещены, они значительно замедляют решение)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хорошее решение требует $O(NM)$ дополнительной памяти вместо $O(NMD)$, где N, M, D — число объектов, точек и размерность пространства соответственно.\n",
    "\n",
    "Подсказка: вы можете вычислить матрицу попарных скалярных произведений между объектами и точками, используя одно матричное умножение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(100, 10)\n",
    "Y = torch.randn(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 4, 0, 2, 3, 2, 2, 2, 0, 1, 1, 0, 2, 2, 3, 4, 4, 0, 1, 1, 1, 3, 2,\n",
       "        0, 0, 2, 0, 2, 4, 0, 3, 2, 1, 1, 2, 3, 4, 0, 4, 1, 0, 1, 2, 2, 1, 3, 1,\n",
       "        2, 2, 2, 1, 0, 2, 0, 1, 4, 1, 0, 4, 4, 3, 4, 2, 2, 2, 2, 1, 1, 2, 4, 2,\n",
       "        2, 1, 0, 1, 1, 2, 0, 2, 4, 2, 0, 4, 3, 3, 3, 0, 1, 0, 0, 4, 3, 2, 1, 2,\n",
       "        0, 2, 4, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((X[:, :, None] - Y.T[None, :, :])**2).sum(axis=1).argmin(axis=1) # O(NMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 4, 0, 2, 3, 2, 2, 2, 0, 1, 1, 0, 2, 2, 3, 4, 4, 0, 1, 1, 1, 3, 2,\n",
       "        0, 0, 2, 0, 2, 4, 0, 3, 2, 1, 1, 2, 3, 4, 0, 4, 1, 0, 1, 2, 2, 1, 3, 1,\n",
       "        2, 2, 2, 1, 0, 2, 0, 1, 4, 1, 0, 4, 4, 3, 4, 2, 2, 2, 2, 1, 1, 2, 4, 2,\n",
       "        2, 1, 0, 1, 1, 2, 0, 2, 4, 2, 0, 4, 3, 3, 3, 0, 1, 0, 0, 4, 3, 2, 1, 2,\n",
       "        0, 2, 4, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-2 * (X @ Y.T) + (Y**2).sum(axis=1)).argmin(axis=1) # O(NM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вычисления на GPU\n",
    "`x.cuda()` копирует тензор на GPU и возвращает результат.\n",
    "Вы можете явно указать индекс GPU, на которую необходимо скопировать тензор: `x.cuda(gpu_id)`.\n",
    "Если тензор уже находится в памяти GPU, то метод вернёт тот же самый тензор, и копирование производиться не будет.\n",
    "`x.cpu()` работает аналогично.\n",
    "\n",
    "Вы можете выставить переменную окружения `CUDA_VISIBLE_DEVICES`.\n",
    "Если она задана, то `gpu_id` должен быть индексом в этом списке видимых GPU.\n",
    "\n",
    "Операции могут быть выполнены только над тензорами, лежащими на одном устройстве.\n",
    "Нарушение этого правила приводит к ошибке.\n",
    "Результат выполнения операции лежит на том же устройстве, что и операнды.\n",
    "\n",
    "Можно использовать `x.device` для определения, где лежит тензор `x` (на CPU или GPU).\n",
    "Для перемещения тензора на устройство также может быть полезен метод `.to`: `y.to(x.device)`.\n",
    "Также большинство методов, создающих тензоры, имеют необязательный параметр `device`, например: `torch.randn(5, device='cuda:0')`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Автоматическое дифференцирование\n",
    "\n",
    "Автоматическое вычисление градиента, используя обратное распространение:\n",
    "\n",
    "1. Создадим тензор/тензоры, требующие вычисление градиента: `a = torch.tensor(..., requires_grad=True)`\n",
    "\n",
    "2. Определим некоторую дифференцируемую _скалярную_ функцию: `loss = whatever(a)`\n",
    "\n",
    "3. Вызовем обратное распространение: `loss.backward()`\n",
    "\n",
    "4. Градиент вычислен и его можно получить так: `a.grad`\n",
    "\n",
    "Заметим, что `loss` должен быть функцией, зависящей как минимум от одного тензора, требующим вычисление градиента (`requires_grad = True`).\n",
    "\n",
    "Подробнее: https://pytorch.org/docs/stable/autograd.html\n",
    "\n",
    "Отличие** между Pytorch и Theano/TensorFlow:\n",
    "\n",
    "1. Функция `loss` может меняться динамически, например, для каждого минибатча.\n",
    "\n",
    "2. После вызова `.backward()`, градиенты созраняются в поле `.grad` каждой переменной. Если вызывать `.backward()` несколько раз или для нескольких функций, зависящих от одной переменной, то `.grad` этой переменной будет содержать сумму градиентов этих функций. Это можно использовать, если необходимо оптимизировать сумму нескольких loss-функций, или для виртуального увеличения размера батча. После каждого шага оптимизации градиенты необходимо обнулять (например, используя `optimizer.zero_grad()`).\n",
    "\n",
    "** - Pytorch поддерживает компилируемые вычислительные графы, что полезно, например, для увеличения производительности в продакшн-системах. Для этого используется <a href=\"https://en.wikipedia.org/wiki/Just-in-time_compilation\">JIT-компиляция</a>. Подробнее: https://pytorch.org/docs/stable/jit.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Простой пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([-1.4923, -2.4517,  1.0345, -0.3183])\n",
      "y: tensor([ 0.3626, -2.9302,  0.3661, -2.1837])\n",
      "dp / dx: tensor([ 0.3626, -2.9302,  0.3661, -2.1837])\n",
      "dp / dy: tensor([-1.4923, -2.4517,  1.0345, -0.3183])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, requires_grad=True)\n",
    "y = torch.randn(4, requires_grad=True)\n",
    "z = x * y + 10\n",
    "p = z.sum()\n",
    "p.backward()\n",
    "print('x:', x.data)\n",
    "print('y:', y.data)\n",
    "print('dp / dx:', x.grad)\n",
    "print('dp / dy:', y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detaching (\"отцепление\") переменных\n",
    "`.detach()` возвращает копию переменной, через которую не проходит обратное распространение.\n",
    "Если вы усредняете или просто сохраняете значения функции потерь на минибатчах, лучше вызвать `.detach()` до сохранения этих значений.\n",
    "Иначе вычислительный граф для каждого минибатча также будет сохраняться в памяти, и очень быстро может возникнуть нехватка оперативной памяти.\n",
    "\n",
    "Также сущесвует in-place версия (`.detach_()`), которая не создаёт копию переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([ 0.6659, -1.8548, -0.5792, -1.1804])\n",
      "y: tensor([-0.1299,  1.1616, -0.8347, -0.6363])\n",
      "dp / dx: tensor([-0.1299,  1.1616, -0.8347, -0.6363])\n",
      "dp / dy: None\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, requires_grad=True)\n",
    "y0 = torch.randn(4, requires_grad=True)\n",
    "y = y0.detach()\n",
    "z = x * y + 10\n",
    "p = z.sum()\n",
    "p.backward()\n",
    "print('x:', x.data)\n",
    "print('y:', y.data)\n",
    "print('dp / dx:', x.grad)\n",
    "print('dp / dy:', y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обнуление градиента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "dp / dx: tensor([2., 2., 2., 2.])\n",
      "x: tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "dp / dx: tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1., 1, 1, 1], requires_grad=True)\n",
    "y = x ** 2\n",
    "p = y.sum()\n",
    "p.backward()\n",
    "print('x:', x)\n",
    "print('dp / dx:', x.grad)\n",
    "y = 1 / x\n",
    "p = y.sum()\n",
    "p.backward()\n",
    "print('x:', x)\n",
    "print('dp / dx:', x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "dp / dx: tensor([2., 2., 2., 2.])\n",
      "x: tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "dp / dx: tensor([-1., -1., -1., -1.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 1, 1, 1.], requires_grad=True)\n",
    "y = x ** 2\n",
    "p = y.sum()\n",
    "p.backward()\n",
    "print('x:', x)\n",
    "print('dp / dx:', x.grad)\n",
    "x.grad.detach_()       # extracting gradient Variable from the previous computational graph (optional)\n",
    "x.grad.zero_()         # zero gradinents\n",
    "y = 1 / x\n",
    "p = y.sum()\n",
    "p.backward()\n",
    "print('x:', x)\n",
    "print('dp / dx:', x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Листовые переменные\n",
    "\n",
    "В целях экономии памяти, градиенты сохраняются только для, так сказать, листовых переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([ 1.4889,  2.7059, -0.7766, -1.1981], requires_grad=True)\n",
      "y: tensor([ 2.4889,  3.7059,  0.2234, -0.1981], grad_fn=<AddBackward0>)\n",
      "p: tensor(6.2200, grad_fn=<SumBackward0>)\n",
      "x.grad: tensor([1., 1., 1., 1.])\n",
      "y.grad: None\n",
      "p.grad: None\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, requires_grad=True)  # листовая переменная\n",
    "y = x + 1                               # нелистовая переменная\n",
    "p = y.sum()                             # нелистовая переменная\n",
    "p.backward()\n",
    "print('x:', x)\n",
    "print('y:', y)\n",
    "print('p:', p)\n",
    "print('x.grad:', x.grad)\n",
    "print('y.grad:', y.grad)\n",
    "print('p.grad:', p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad: tensor([1., 1., 1., 1.])\n",
      "y.grad: tensor([1., 1., 1., 1.])\n",
      "z.grad: None\n",
      "p.grad: None\n",
      "x.is_leaf: True\n",
      "y.is_leaf: True\n",
      "z.is_leaf: False\n",
      "p.is_leaf: False\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, requires_grad=True)  # листовая переменная\n",
    "y = torch.randn(4, requires_grad=True)  # листовая переменная\n",
    "z = x + y    # нелистовая переменная\n",
    "p = z.sum()  # нелистовая переменная\n",
    "p.backward()\n",
    "print('x.grad:', x.grad)\n",
    "print('y.grad:', y.grad)\n",
    "print('z.grad:', z.grad)\n",
    "print('p.grad:', p.grad)\n",
    "print('x.is_leaf:', x.is_leaf)\n",
    "print('y.is_leaf:', y.is_leaf)\n",
    "print('z.is_leaf:', z.is_leaf)\n",
    "print('p.is_leaf:', p.is_leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вычисление градиент для нелистовых переменных\n",
    "\n",
    "Чтобы сохранить градиент для нелистовой переменной, можно использовать метод `.retain_grad()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dp / dx: tensor([-1.3983, -0.6819,  1.0731, -3.3659])\n",
      "dp / dz: tensor([-1.7472,  0.2496,  2.0024,  0.9872])\n",
      "dp / dw: tensor([-0.8736,  0.1248,  1.0012,  0.4936])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, requires_grad=True)   # листовая переменная\n",
    "z = torch.randn(4, requires_grad=True)   # листовая переменная\n",
    "w = z * 2      # нелистовая переменная\n",
    "y = x * w + 1  # вычисление до вызова retain_grad - это ок\n",
    "p = y.sum()\n",
    "\n",
    "w.retain_grad()\n",
    "\n",
    "p.backward()\n",
    "print('dp / dx:', x.grad)\n",
    "print('dp / dz:', z.grad)\n",
    "print('dp / dw:', w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что даже если существуют нелистовые переменные, требующие вычисление градиента, при вызове `.backward()` может произойти ошибка, если нет листовых переменных, требущих градиент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # такой код не работает\n",
    "# x = torch.randn(4, requires_grad=False)   # листовая переменная\n",
    "# z = torch.randn(4, requires_grad=False)   # листовая переменная\n",
    "# w = z * 2      # нелистовая переменная\n",
    "# y = x * w + 1\n",
    "# p = y.sum()\n",
    "\n",
    "# w.retain_grad()\n",
    "\n",
    "# p.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание #2: Оптимизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(50, 10)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "W = torch.randn(10, 2, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам дана немного странная лосс-функция, которая задаёт преобразование 10-мерного пространства точек в 2-мерную окружность радиуса 1. Вам необходимо использовать градиентный спуск для подбора параметр данного преобразования.\n",
    "\n",
    "Линейное преобразование точки в 10-мерном пространстве $x$ в точку в 2-мерном пространстве $y$ задаётся матрицей весов $W$ и вектором $b$ следующим образом:\n",
    "$$y = Wx + b$$\n",
    "\n",
    "Рассмотрим Евклидову норму в 2-мерном пространстве:\n",
    "$$||y||_2 = \\sqrt{y_1^2 + y_2^2}$$\n",
    "\n",
    "Лосс-функция $f_0$ штрафует за расстояние от точки $y$ до окружности радиуса 1:\n",
    "$$f_0(x, W, b) = 0.5 \\cdot \\big| ||y||_2 - 1 \\big| + \\big( ||y||_2 - 1 \\big)^2$$\n",
    "\n",
    "К сожалению, оптимизация $f_0$ по $W$ и $b$ может быть получена аналитически и ведёт к тривиальному решению $W = 0$, $b = (1, 0)$.\n",
    "Чтобы обойти такие решения мы введём штраф за близость $y$ к $b$. Эта лосс-функция обращается в $0$, если расстояние от точки $y$ до точки $b$ больше, чем $1$:\n",
    "$$f_1(x, W, b) = \\max\\big(0, \\frac{1}{||y - b||_2} - 1\\big)$$\n",
    "\n",
    "Итоговая лосс-функция задаётся следующим образом:\n",
    "$$f(x, W, b) = f_0(x, W, b) + f_1(x, W, b)$$\n",
    "\n",
    "И нужно решить следующую задачу оптимизации:\n",
    "$$\\frac{1}{N}\\sum\\limits_{i = 1}^N f(x_i, W, b) \\to \\min\\limits_{W, b}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X, W, b):\n",
    "    n = X.shape[0]\n",
    "    y = X @ W + b\n",
    "    t = torch.norm(y, dim=1) - 1\n",
    "    f0 = 0.5 * t.abs() + t**2\n",
    "    f1 = torch.max(torch.zeros(n), 1 / torch.norm(y - b, dim=1) - 1)\n",
    "    f = f0 + f1\n",
    "    return f.sum() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.4954, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f(X, W, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x11f32c550>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "Y = X.mm(W.detach()).add(b.detach())\n",
    "plt.scatter(Y[:, 0], Y[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.4954)\n",
      "tensor(12.6940)\n",
      "tensor(7.3749)\n",
      "tensor(4.6916)\n",
      "tensor(3.2148)\n",
      "tensor(2.3453)\n",
      "tensor(1.7691)\n",
      "tensor(1.3856)\n",
      "tensor(1.1313)\n",
      "tensor(0.9553)\n",
      "tensor(0.8305)\n",
      "tensor(0.7370)\n",
      "tensor(0.6672)\n",
      "tensor(0.6207)\n",
      "tensor(0.5826)\n",
      "tensor(0.5525)\n",
      "tensor(0.5289)\n",
      "tensor(0.5113)\n",
      "tensor(0.4971)\n",
      "tensor(0.4850)\n",
      "tensor(0.4748)\n",
      "tensor(0.4664)\n",
      "tensor(0.4586)\n",
      "tensor(0.4522)\n",
      "tensor(0.4470)\n",
      "tensor(0.4422)\n",
      "tensor(0.4385)\n",
      "tensor(0.4349)\n",
      "tensor(0.4307)\n",
      "tensor(0.4275)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "\n",
    "for i in range(30):\n",
    "    l = f(X, W, b)\n",
    "    print(l.detach())\n",
    "    l.backward()\n",
    "    W.data -= lr * W.grad.data\n",
    "    b.data -= lr * b.grad.data\n",
    "    W.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x11f43a7f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "Y = X.mm(W.detach()).add(b.detach())\n",
    "plt.scatter(Y[:, 0], Y[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Время реализовать нейронную сеть\n",
    "\n",
    "Здесь мы реализуем многослойный перцептрон без использования модуля torch.nn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 64), (1797,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1347, 64), (450, 64))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "X_test = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсказка: нейронный сети тяжело учатся, если входы имеют огромные абсолютные значения. Поэтому до обучения каждый признак необходимо нормализовать, причём независимо (исключение составляют свёрточные сети, для них нормализация производится независимо по каналам).\n",
    "\n",
    "Существует множество способов нормализации данных. Одним из самых популярных - это вычитание среднего и деление результата на стандартное отклонение (этот метод должен быть использован аккуратно, если стандартное отклонение близко к нулю; лучше обрабатывать эти случаи отдельно).\n",
    "Другими популярными способома является вычитание минимума и деление на разницу между максимумом и минимумом, применение сигмоидной функции и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте нормализацию данных здесь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "std[std == 0] = 1\n",
    "X_train = (X_train - mu) / std\n",
    "X_test = (X_test - mu) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear layer implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        self.training = True\n",
    "        self.children = []\n",
    "\n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __call__(self, *input):\n",
    "        return self.forward(*input)\n",
    "\n",
    "    def parameters(self):\n",
    "        \"\"\"Returns list of parameters of module and its children.\"\"\"\n",
    "        res = []\n",
    "        for submodule in self.children:\n",
    "            res += submodule.parameters()\n",
    "        for param in res:\n",
    "            if not isinstance(param, torch.Tensor):\n",
    "                raise Exception('Parameters must be Tensors.')\n",
    "            if not param.requires_grad:\n",
    "                raise Exception('Parameters must require gradients.')\n",
    "        return res\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"Sets gradients of all model parameters to zero.\"\"\"\n",
    "        for p in self.parameters():\n",
    "            if p.grad is not None:\n",
    "                p.grad.detach_()   # detachs gradient Variable from the computational graph\n",
    "                p.grad.zero_()\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Sets module into train mode (for DropOut, BatchNorm, etc).\"\"\"\n",
    "        self.training = True\n",
    "        for submodule in self.children:\n",
    "            submodule.train()\n",
    "\n",
    "    def eval(self):\n",
    "        \"\"\"Sets module into evaluation mode.\"\"\"\n",
    "        self.training = False\n",
    "        for submodule in self.children:\n",
    "            submodule.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Module):\n",
    "    def __init__(self, input_units, output_units):\n",
    "        \"\"\"A dense layer is a layer which performs a learned affine transformation:\n",
    "        f(x) = W x + b\n",
    "        \"\"\"\n",
    "        super(Dense, self).__init__()\n",
    "        # initialize weights with small random numbers from normal distribution\n",
    "        scale = np.sqrt(2 / (input_units + output_units))\n",
    "        self.weights = torch.randn(input_units, output_units, requires_grad=True)\n",
    "        self.biases = torch.randn(output_units, requires_grad=True)\n",
    "        self.weights.data *= scale\n",
    "        self.biases.data *= scale\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weights, self.biases]\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \"\"\"Performs an affine transformation:\n",
    "        f(x) = W x + b\n",
    "        input shape:  [batch, input_units]  (Tensor)\n",
    "        output shape: [batch, output units] (Tensor)\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        output = input @ self.weights + self.biases\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"ReLU layer simply applies elementwise rectified linear unit to all inputs.\"\"\"\n",
    "        super(ReLU, self).__init__()\n",
    "\n",
    "    def parameters(self):\n",
    "        return []  # ReLU has no parameters\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"Applies elementwise ReLU to [batch, num_units] Tensor matrix.\"\"\"\n",
    "        # your code here\n",
    "        return input * (input > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogSoftmax(Module):\n",
    "    def __init__(self):\n",
    "        super(LogSoftmax, self).__init__()\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \"\"\"Applies softmax to each row and then applies component-wise log.\n",
    "        Input shape:  [batch, num_units] (Tensor)\n",
    "        Output shape: [batch, num_units] (Tensor)\n",
    "        \"\"\"\n",
    "        output = input.exp() / (input.exp().sum(-1)).unsqueeze(-1)\n",
    "        return output.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetwork(Module):\n",
    "    def __init__(self, input_size, hidden_layers_size, hidden_layers_number, output_size):\n",
    "        super(MyNetwork, self).__init__()\n",
    "\n",
    "        network = []\n",
    "        network.append(Dense(input_size, hidden_layers_size))\n",
    "        network.append(ReLU())\n",
    "        for i in range(hidden_layers_number - 1):\n",
    "            network.append(Dense(hidden_layers_size, hidden_layers_size))\n",
    "            network.append(ReLU())\n",
    "        network.append(Dense(hidden_layers_size, output_size))\n",
    "        network.append(LogSoftmax())\n",
    "\n",
    "        self.children = network\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Applies all layers of neural network to the input.\n",
    "        Input shape:  [batch, num_units] (Tensor)\n",
    "        Output shape: [batch, num_units] (Tensor)\n",
    "        \"\"\"\n",
    "        for child in self.children:\n",
    "            input = child(input)\n",
    "        \n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossentropy(activations, target):\n",
    "    \"\"\"Returns negative log-likelihood of target under model\n",
    "    represented by activations (log probabilities of classes).\n",
    "    Tip: it is better to average crossentropy among objects\n",
    "    instead of sum.\n",
    "    Activations shape: [batch, num_classes] (Tensor)\n",
    "    Target shape:      [batch]              (Tensor)\n",
    "    Output shape: 1 (scalar, Tensor)\n",
    "    \"\"\"\n",
    "    return -activations[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDOptimizer:\n",
    "    def __init__(self, parameters, learning_rate):\n",
    "        self.parameters = parameters\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Make one optimization step for parameters in-place.\n",
    "        Assumes that all parameters are Variable with computed gradient.\n",
    "        \"\"\"\n",
    "        for param in self.parameters:\n",
    "            param.data -= self.learning_rate * param.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(dataset, network, prefix='Test loss:', optimizer=None, verbose=True):\n",
    "    # Change mode for all layers.\n",
    "    if optimizer:\n",
    "        network.train()\n",
    "    else:\n",
    "        network.eval()\n",
    "\n",
    "    batch_size = 100\n",
    "    batchgenerator = torch.utils.data.DataLoader(dataset, batch_size, True)\n",
    "\n",
    "    avg_loss = 0\n",
    "    for i, (batch_data, batch_target) in enumerate(batchgenerator):\n",
    "        if optimizer:\n",
    "            network.zero_grad()\n",
    "        batch_output = network(batch_data)\n",
    "        batch_loss = crossentropy(batch_output, batch_target)\n",
    "        batch_loss.backward()\n",
    "        batch_loss = float(batch_loss)\n",
    "        avg_loss += (batch_loss - avg_loss) / (i + 1)\n",
    "        if optimizer:\n",
    "            optimizer.step()\n",
    "    if verbose:\n",
    "        print(prefix, avg_loss, flush=True)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.0738722043378015\n",
      "Test loss: 0.39690343737602235\n",
      "Train loss: 0.27585516976458685\n",
      "Test loss: 0.23463469445705415\n",
      "Train loss: 0.17370419363890374\n",
      "Test loss: 0.18251388818025588\n",
      "Train loss: 0.12697122458900723\n",
      "Test loss: 0.18071738481521607\n",
      "Train loss: 0.09623066069824356\n",
      "Test loss: 0.1420673429965973\n",
      "Train loss: 0.07602805112089431\n",
      "Test loss: 0.13975680470466614\n",
      "Train loss: 0.06355450355580874\n",
      "Test loss: 0.12768156975507736\n",
      "Train loss: 0.0538682486595852\n",
      "Test loss: 0.13825826495885848\n",
      "Train loss: 0.04893994717193502\n",
      "Test loss: 0.11748176626861095\n",
      "Train loss: 0.03988778897161994\n",
      "Test loss: 0.11313324347138405\n",
      "Train loss: 0.035739601456693235\n",
      "Test loss: 0.11637146770954132\n",
      "Train loss: 0.031891934241035154\n",
      "Test loss: 0.13019417151808738\n",
      "Train loss: 0.027689510357699225\n",
      "Test loss: 0.12836344987154008\n",
      "Train loss: 0.025144671489085474\n",
      "Test loss: 0.11398202925920486\n",
      "Train loss: 0.02353823444406901\n",
      "Test loss: 0.11843206137418746\n",
      "Train loss: 0.020749252089964493\n",
      "Test loss: 0.10640302076935768\n",
      "Train loss: 0.018873344840747968\n",
      "Test loss: 0.1150386467576027\n",
      "Train loss: 0.017265460520450557\n",
      "Test loss: 0.11008773669600487\n",
      "Train loss: 0.016112216282635927\n",
      "Test loss: 0.10631147734820842\n",
      "Train loss: 0.015153263030307635\n",
      "Test loss: 0.10782913118600845\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "network = MyNetwork(X_train.shape[1], 32, 0, 10)\n",
    "sgd = SGDOptimizer(network.parameters(), 0.5)\n",
    "\n",
    "num_epochs = 20\n",
    "sgd_train_losses = []\n",
    "sgd_test_losses = []\n",
    "for i in range(num_epochs):\n",
    "    loss = run_epoch(train_dataset, network, 'Train loss:', sgd)\n",
    "    sgd_train_losses.append(loss)\n",
    "    loss = run_epoch(test_dataset, network, 'Test loss:',  None)\n",
    "    sgd_test_losses.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нужно больше оптимизаторов!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDMomentumOptimizer:\n",
    "    def __init__(self, parameters, learning_rate=0.01, momentum=0.9):\n",
    "        self.parameters = parameters\n",
    "        self.prev_grads = [torch.zeros_like(param.data) for param in parameters]\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "    \n",
    "    def step(self):\n",
    "        \"\"\"Make one optimization step for parameters in-place.\n",
    "        Assumes that all parameters are Variable with computed gradient.\n",
    "        \"\"\"\n",
    "        for i, param in enumerate(self.parameters):\n",
    "            grad = self.momentum * self.prev_grads[i] + (1 - self.momentum) * param.grad.data\n",
    "            self.prev_grads[i] = torch.clone(grad).detach()\n",
    "            param.data -= self.learning_rate * grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSPropOptimizer:\n",
    "    def __init__(self, parameters, learning_rate=0.01, beta=0.9, eps=1e-8):\n",
    "        self.parameters = parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta = beta\n",
    "        self.eps = eps\n",
    "        self.prev_grads = [torch.zeros_like(param.data) for param in parameters]\n",
    "        \n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Make one optimization step for parameters in-place.\n",
    "        Assumes that all parameters are Variable with computed gradient.\n",
    "        \"\"\"\n",
    "        for i, param in enumerate(self.parameters):\n",
    "            grad = self.beta * self.prev_grads[i] + (1 - self.beta) * param.grad.data**2\n",
    "            self.prev_grads[i] = torch.clone(grad).detach()\n",
    "            param.data -= self.learning_rate * param.grad.data / (torch.sqrt(grad) + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptimizer:\n",
    "    def __init__(self, parameters, learning_rate=0.01, beta1=0.9, beta2=0.999, eps=1e-8):\n",
    "        self.parameters = parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        self.t = 0\n",
    "        self.prev_m1 = [torch.zeros_like(param.data) for param in parameters]\n",
    "        self.prev_m2 = [torch.zeros_like(param.data) for param in parameters]\n",
    "        \n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Make one optimization step for parameters in-place.\n",
    "        Assumes that all parameters are Variable with computed gradient.\n",
    "        \"\"\"\n",
    "        for i, param in enumerate(self.parameters):\n",
    "            self.t += 1\n",
    "            m1 = self.beta1 * self.prev_m1[i] + (1 - self.beta1) * param.grad.data\n",
    "            m2 = self.beta2 * self.prev_m2[i] + (1 - self.beta2) * param.grad.data**2\n",
    "            self.prev_m1[i] = torch.clone(m1).detach()\n",
    "            self.prev_m2[i] = torch.clone(m2).detach()\n",
    "            m1_est = m1 / (1 - self.beta1**self.t)\n",
    "            m2_est = m2 / (1 - self.beta2**self.t)\n",
    "            param.data -= self.learning_rate * m1_est / (torch.sqrt(m2_est) + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6958270626408716\n",
      "Test loss: 0.7480188727378845\n",
      "Train loss: 0.4208430573344231\n",
      "Test loss: 0.3091982066631317\n",
      "Train loss: 0.1971336587199143\n",
      "Test loss: 0.21233940720558167\n",
      "Train loss: 0.12416990952832357\n",
      "Test loss: 0.18100107610225677\n",
      "Train loss: 0.09022074272590022\n",
      "Test loss: 0.16313549131155014\n",
      "Train loss: 0.07277351032410348\n",
      "Test loss: 0.15219417810440064\n",
      "Train loss: 0.060348318889737115\n",
      "Test loss: 0.14517679214477539\n",
      "Train loss: 0.049973036628216505\n",
      "Test loss: 0.14082070887088777\n",
      "Train loss: 0.04323660529085568\n",
      "Test loss: 0.14102438539266587\n",
      "Train loss: 0.03951005371553558\n",
      "Test loss: 0.14091340005397796\n",
      "Train loss: 0.03384363418444991\n",
      "Test loss: 0.13342302814126014\n",
      "Train loss: 0.030114314119730676\n",
      "Test loss: 0.13509950041770935\n",
      "Train loss: 0.02700126071327499\n",
      "Test loss: 0.13655895367264748\n",
      "Train loss: 0.02427194526951228\n",
      "Test loss: 0.1318156123161316\n",
      "Train loss: 0.021663252862968614\n",
      "Test loss: 0.13209424763917924\n",
      "Train loss: 0.020337276692901342\n",
      "Test loss: 0.12267234902828932\n",
      "Train loss: 0.019141408082629954\n",
      "Test loss: 0.1349826917052269\n",
      "Train loss: 0.017405308916100433\n",
      "Test loss: 0.14312571585178374\n",
      "Train loss: 0.01577558082395366\n",
      "Test loss: 0.14957162439823152\n",
      "Train loss: 0.014658772320087467\n",
      "Test loss: 0.1319822996854782\n"
     ]
    }
   ],
   "source": [
    "network = MyNetwork(X_train.shape[1], 32, 1, 10)\n",
    "optim = SGDMomentumOptimizer(network.parameters(), 0.5)\n",
    "\n",
    "num_epochs = 20\n",
    "sgd_momentum_train_losses = []\n",
    "sgd_momentum_test_losses = []\n",
    "for i in range(num_epochs):\n",
    "    loss = run_epoch(train_dataset, network, 'Train loss:', optim)\n",
    "    sgd_momentum_train_losses.append(loss)\n",
    "    loss = run_epoch(test_dataset, network, 'Test loss:',  None)\n",
    "    sgd_momentum_test_losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.9790757681642258\n",
      "Test loss: 0.3951204180717468\n",
      "Train loss: 0.23220155867082734\n",
      "Test loss: 0.2063836932182312\n",
      "Train loss: 0.1290872735636575\n",
      "Test loss: 0.16445472538471223\n",
      "Train loss: 0.08060296358806748\n",
      "Test loss: 0.17376239523291587\n",
      "Train loss: 0.050573181627052176\n",
      "Test loss: 0.12922589480876923\n",
      "Train loss: 0.03436283195125205\n",
      "Test loss: 0.13724106475710868\n",
      "Train loss: 0.01991265776034977\n",
      "Test loss: 0.13394027352333068\n",
      "Train loss: 0.014086459829871143\n",
      "Test loss: 0.12088451087474823\n",
      "Train loss: 0.008846274992850211\n",
      "Test loss: 0.10804536379873753\n",
      "Train loss: 0.00559002931030201\n",
      "Test loss: 0.12573828510940074\n",
      "Train loss: 0.003504674682127578\n",
      "Test loss: 0.13146790042519568\n",
      "Train loss: 0.0025946373435934743\n",
      "Test loss: 0.13872359171509743\n",
      "Train loss: 0.0016802318693537796\n",
      "Test loss: 0.11778247207403184\n",
      "Train loss: 0.0009036163371222626\n",
      "Test loss: 0.11718433005735278\n",
      "Train loss: 0.0006120544733546142\n",
      "Test loss: 0.14635447338223456\n",
      "Train loss: 0.0007426519109035975\n",
      "Test loss: 0.18286193981766702\n",
      "Train loss: 0.00032041407705816837\n",
      "Test loss: 0.15994852259755135\n",
      "Train loss: 0.0001590274543039933\n",
      "Test loss: 0.13619787946809084\n",
      "Train loss: 0.00010690530299533357\n",
      "Test loss: 0.1780679114162922\n",
      "Train loss: 7.625162301597552e-05\n",
      "Test loss: 0.15385001264512538\n"
     ]
    }
   ],
   "source": [
    "network = MyNetwork(X_train.shape[1], 32, 1, 10)\n",
    "optim = RMSPropOptimizer(network.parameters())\n",
    "\n",
    "num_epochs = 20\n",
    "rmsprop_train_losses = []\n",
    "rmsprop_test_losses = []\n",
    "for i in range(num_epochs):\n",
    "    loss = run_epoch(train_dataset, network, 'Train loss:', optim)\n",
    "    rmsprop_train_losses.append(loss)\n",
    "    loss = run_epoch(test_dataset, network, 'Test loss:',  None)\n",
    "    rmsprop_test_losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.4429009939943038\n",
      "Test loss: 0.5804416418075562\n",
      "Train loss: 0.30385231785476213\n",
      "Test loss: 0.23656160831451417\n",
      "Train loss: 0.12539377915007727\n",
      "Test loss: 0.2193530261516571\n",
      "Train loss: 0.06185844593814441\n",
      "Test loss: 0.15878635719418527\n",
      "Train loss: 0.040604921856096814\n",
      "Test loss: 0.15491996482014656\n",
      "Train loss: 0.02442644563104425\n",
      "Test loss: 0.1518046647310257\n",
      "Train loss: 0.015586350711860826\n",
      "Test loss: 0.16484163627028464\n",
      "Train loss: 0.011006047816148827\n",
      "Test loss: 0.15084458217024804\n",
      "Train loss: 0.008942971238866448\n",
      "Test loss: 0.1462010622024536\n",
      "Train loss: 0.007348121376708152\n",
      "Test loss: 0.15473982319235802\n",
      "Train loss: 0.005675997235812248\n",
      "Test loss: 0.14033473581075667\n",
      "Train loss: 0.0048460578545928\n",
      "Test loss: 0.14714743494987487\n",
      "Train loss: 0.004085443672790591\n",
      "Test loss: 0.14160461872816085\n",
      "Train loss: 0.0037329845196966615\n",
      "Test loss: 0.13714438378810884\n",
      "Train loss: 0.003270971913090242\n",
      "Test loss: 0.1403486594557762\n",
      "Train loss: 0.0029153793667709193\n",
      "Test loss: 0.13878582715988158\n",
      "Train loss: 0.0026150427293032408\n",
      "Test loss: 0.13891809284687043\n",
      "Train loss: 0.00234099815133959\n",
      "Test loss: 0.13716023936867713\n",
      "Train loss: 0.002161615719420037\n",
      "Test loss: 0.13847110308706762\n",
      "Train loss: 0.0020491786251243737\n",
      "Test loss: 0.1392690259963274\n"
     ]
    }
   ],
   "source": [
    "network = MyNetwork(X_train.shape[1], 32, 1, 10)\n",
    "optim = AdamOptimizer(network.parameters())\n",
    "\n",
    "num_epochs = 20\n",
    "adam_train_losses = []\n",
    "adam_test_losses = []\n",
    "for i in range(num_epochs):\n",
    "    loss = run_epoch(train_dataset, network, 'Train loss:', optim)\n",
    "    adam_train_losses.append(loss)\n",
    "    loss = run_epoch(test_dataset, network, 'Test loss:',  None)\n",
    "    adam_test_losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sgd_train_losses, label='SGD train')\n",
    "plt.plot(sgd_test_losses, label='SGD test')\n",
    "plt.plot(sgd_momentum_train_losses, label='SGD momentum train')\n",
    "plt.plot(sgd_momentum_test_losses, label='SGD momentum test')\n",
    "plt.plot(rmsprop_train_losses, label='Rmsprop train')\n",
    "plt.plot(rmsprop_test_losses, label='Rmsprop test')\n",
    "plt.plot(adam_train_losses, label='Adam train')\n",
    "plt.plot(adam_test_losses, label='Adam test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DropOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseWithDropOut(Module):\n",
    "    def __init__(self, input_units, output_units, dropout_rate, nonlinearity):\n",
    "        \"\"\"A dense layer is a layer which performs a learned\n",
    "        affine transformation and applies dropout:\n",
    "        m ~ Bernoulli(1 - p, size=output_units)\n",
    "        f(x) = g(W x + b) o m\n",
    "        \"\"\"\n",
    "        super(DenseWithDropOut, self).__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.nonlinearity = nonlinearity\n",
    "        \n",
    "        scale = np.sqrt(2 / (input_units + output_units))\n",
    "        self.weights = torch.randn(input_units, output_units, requires_grad=True)\n",
    "        self.biases = torch.randn(output_units, requires_grad=True)\n",
    "        self.weights.data *= scale\n",
    "        self.biases.data *= scale\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weights, self.biases]\n",
    "        \n",
    "    def forward(self, input, training=True):\n",
    "        \"\"\"Performs an affine transformation with dropout.\n",
    "        In training mode:\n",
    "        m ~ Bernoulli(1 - p, size=output_units)\n",
    "        f(x) = g(W x + b) o m\n",
    "        In evaluation mode:\n",
    "        f(x) = g(W x + b) (1 - p)\n",
    "        input shape:  [batch, input_units]  (Variable)\n",
    "        output shape: [batch, output units] (Variable)\n",
    "        \"\"\"\n",
    "        output = self.nonlinearity(input @ self.weights + self.biases)\n",
    "        \n",
    "        if training:\n",
    "            m = np.random.binomial(n=1, p=1-self.dropout_rate, size=self.weights.shape[1])\n",
    "            output = output * torch.tensor(m)\n",
    "        else:\n",
    "            output = output * (1 - self.dropout_rate)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, правда ли полносвязная сеть с dropout работает быстрее, чем обычная полносвязная сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.39 s ± 946 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "5.99 s ± 518 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "width = 2000\n",
    "network1 = [\n",
    "    DenseWithDropOut(width, width, 0.9, lambda x: ReLU().forward(x)),\n",
    "    DenseWithDropOut(width, width, 0.9, lambda x: ReLU().forward(x)),\n",
    "    DenseWithDropOut(width, width, 0.9, lambda x: ReLU().forward(x)),\n",
    "    DenseWithDropOut(width, 1, 0, lambda x: x)\n",
    "]\n",
    "network2 = [\n",
    "    Dense(width, width),\n",
    "    ReLU(),\n",
    "    Dense(width, width),\n",
    "    ReLU(),\n",
    "    Dense(width, width),\n",
    "    ReLU(),\n",
    "    Dense(width, 1)\n",
    "]\n",
    "\n",
    "X = torch.randn(10000, width)\n",
    "\n",
    "# check whether DenseWithDropOut works faster than Dense\n",
    "def test_network(network):\n",
    "    x = torch.clone(X)\n",
    "    for layer in network:\n",
    "        x = layer.forward(x)\n",
    "    x.mean().backward()\n",
    "    for layer in network:\n",
    "        x = layer.zero_grad()\n",
    "\n",
    "test_network(network1)\n",
    "%timeit test_network(network1)\n",
    "%timeit test_network(network2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для менее глубоких сетей, низких коэффициентов dropout и меньших размеров минибатча увеличение производительности не такое значительное или его может не быть вообще."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
